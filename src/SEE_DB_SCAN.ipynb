{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rpy2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m silhouette_score\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrpy2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrobjects\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mrobjects\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrpy2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrobjects\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pandas2ri\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrpy2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrobjects\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpackages\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m importr\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'rpy2'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "def load_adherer_data():\n",
    "    \"\"\"\n",
    "    Load medication events data from AdhereR package\n",
    "    \"\"\"\n",
    "    # Activate pandas-R conversion\n",
    "    pandas2ri.activate()\n",
    "    \n",
    "    # Import AdhereR package\n",
    "    adherer = importr('AdhereR')\n",
    "    \n",
    "    # Get med.events dataset\n",
    "    med_events = robjects.r('med.events')\n",
    "    \n",
    "    # Convert to pandas DataFrame\n",
    "    df = pandas2ri.rpy2py(med_events)\n",
    "    \n",
    "    # Convert column names to match the example\n",
    "    df.columns = ['pnr', 'eksd', 'perday', 'ATC', 'dur_original']\n",
    "    \n",
    "    # Convert date column\n",
    "    df['eksd'] = pd.to_datetime(df['eksd'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def analyze_medication(data, medication_code):\n",
    "    \"\"\"\n",
    "    Analyze a specific medication using Sessa's method\n",
    "    \"\"\"\n",
    "    # Filter for specific medication\n",
    "    med_data = data[data['ATC'] == medication_code].copy()\n",
    "    \n",
    "    # Sort by patient and date\n",
    "    med_data = med_data.sort_values(['pnr', 'eksd'])\n",
    "    \n",
    "    # Calculate intervals between prescriptions\n",
    "    med_data['prev_eksd'] = med_data.groupby('pnr')['eksd'].shift(1)\n",
    "    med_data['event_interval'] = (med_data['eksd'] - med_data['prev_eksd']).dt.days\n",
    "    \n",
    "    # Remove rows with NA intervals\n",
    "    med_data = med_data.dropna(subset=['event_interval'])\n",
    "    \n",
    "    # Calculate ECDF\n",
    "    sorted_intervals = np.sort(med_data['event_interval'])\n",
    "    ecdf = np.arange(1, len(sorted_intervals) + 1) / len(sorted_intervals)\n",
    "    \n",
    "    # Keep only lower 80% of ECDF\n",
    "    mask = ecdf <= 0.8\n",
    "    filtered_intervals = sorted_intervals[mask]\n",
    "    \n",
    "    return med_data, filtered_intervals\n",
    "\n",
    "def cluster_intervals(intervals, method='kmeans'):\n",
    "    \"\"\"\n",
    "    Cluster the intervals using either K-means or DBSCAN\n",
    "    \"\"\"\n",
    "    # Scale the data\n",
    "    X = StandardScaler().fit_transform(intervals.reshape(-1, 1))\n",
    "    \n",
    "    if method == 'kmeans':\n",
    "        # Find optimal number of clusters using silhouette score\n",
    "        best_score = -1\n",
    "        best_k = 2\n",
    "        for k in range(2, min(10, len(intervals))):\n",
    "            kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "            labels = kmeans.fit_predict(X)\n",
    "            score = silhouette_score(X, labels)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_k = k\n",
    "        \n",
    "        # Perform final clustering\n",
    "        kmeans = KMeans(n_clusters=best_k, random_state=42)\n",
    "        labels = kmeans.fit_predict(X)\n",
    "        \n",
    "    else:  # DBSCAN\n",
    "        dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "        labels = dbscan.fit_predict(X)\n",
    "    \n",
    "    return labels\n",
    "\n",
    "def main_analysis():\n",
    "    \"\"\"\n",
    "    Main analysis function\n",
    "    \"\"\"\n",
    "    # Load AdhereR data\n",
    "    print(\"Loading AdhereR data...\")\n",
    "    data = load_adherer_data()\n",
    "    \n",
    "    # Get unique medications\n",
    "    medications = data['ATC'].unique()\n",
    "    print(f\"Found {len(medications)} unique medications\")\n",
    "    \n",
    "    # Analyze first two medications\n",
    "    for med in medications[:2]:\n",
    "        print(f\"\\nAnalyzing medication {med}\")\n",
    "        \n",
    "        # Get processed data\n",
    "        med_data, filtered_intervals = analyze_medication(data, med)\n",
    "        \n",
    "        # Perform both clustering methods\n",
    "        kmeans_labels = cluster_intervals(filtered_intervals, 'kmeans')\n",
    "        dbscan_labels = cluster_intervals(filtered_intervals, 'dbscan')\n",
    "        \n",
    "        # Create visualizations\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # Plot original distribution\n",
    "        sns.histplot(data=med_data, x='event_interval', ax=ax1)\n",
    "        ax1.set_title(f'Distribution of intervals for {med}')\n",
    "        \n",
    "        # Plot ECDF\n",
    "        sorted_intervals = np.sort(med_data['event_interval'])\n",
    "        ecdf = np.arange(1, len(sorted_intervals) + 1) / len(sorted_intervals)\n",
    "        ax2.plot(sorted_intervals, ecdf)\n",
    "        ax2.axhline(y=0.8, color='r', linestyle='--')\n",
    "        ax2.set_title('ECDF with 80% cutoff')\n",
    "        \n",
    "        # Plot K-means clusters\n",
    "        for cluster in np.unique(kmeans_labels):\n",
    "            cluster_data = filtered_intervals[kmeans_labels == cluster]\n",
    "            sns.kdeplot(data=cluster_data, ax=ax3)\n",
    "        ax3.set_title('K-means clustering')\n",
    "        \n",
    "        # Plot DBSCAN clusters\n",
    "        for cluster in np.unique(dbscan_labels):\n",
    "            if cluster != -1:  # Skip noise points\n",
    "                cluster_data = filtered_intervals[dbscan_labels == cluster]\n",
    "                sns.kdeplot(data=cluster_data, ax=ax4)\n",
    "        ax4.set_title('DBSCAN clustering')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'medication_{med}_analysis.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # Calculate statistics for each cluster\n",
    "        for method, labels in [('K-means', kmeans_labels), ('DBSCAN', dbscan_labels)]:\n",
    "            print(f\"\\n{method} clustering results:\")\n",
    "            for cluster in np.unique(labels):\n",
    "                if cluster != -1:  # Skip noise points for DBSCAN\n",
    "                    cluster_data = filtered_intervals[labels == cluster]\n",
    "                    print(f\"Cluster {cluster}:\")\n",
    "                    print(f\"  Size: {len(cluster_data)}\")\n",
    "                    print(f\"  Median interval: {np.median(cluster_data):.1f} days\")\n",
    "                    print(f\"  Mean interval: {np.mean(cluster_data):.1f} days\")\n",
    "                    print(f\"  Std deviation: {np.std(cluster_data):.1f} days\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_analysis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
